---
layout: post
title: python多进程处理文件
categories: 茶话会
tags: 茶话会 python
author: nsf
---

* content
{:toc}

分块读取文件



## 文件内容示例

```
95378000,50
24653000,35
51001000,12
1000,20
50425210,11248750
95378000,49
3000,49
3000,50
2000,10
50425210,11248750
```

## 代码

```
"""
*!
* Task 1.
* 我们希望你实现 task1() 这个函数, 它把 rows 中所有满足 b >= 10 && b < 50 并且 a == 1000 || a == 2000 || a == 3000 的行的内容都打印到终端.
* -------------------------------
* Task 2.
* 在任务 1 的基础上, 如果输入的参数 rows 已经按照 (a,b) 进行过排序, 请实现 task2() , 对task1() 的执行性能进行优化. 示例输入 (再次提醒, 实际输入为海量数据):
* 例如sorted_rows =[{ 'a':1000, 'b':31 },{ 'a':1000, 'b':72 },{ 'a':1500, 'b':12 },{ 'a':1500, 'b':34 },{ 'a':2000, 'b':22 },{ 'a':2000, 'b':33 }];
* 输出：
* 1000,31
* 2000,22
* 2000,33
* -------------------------------
* Task 3.
* 在任务 2 的基础上, 我们期望你打印出的匹配行是按照 b 列进行排序的, 请实现 task3() . 示例输出:
* 2000,22
* 1000,31
* 2000,33
* ----------------------------------
* Task 4.
* 在任务 3 的基础上, 如果 a 列上的匹配条件不只是 1000,2000,3000 , 而是扩充成1000,2000,3000,...,98000,99000 , 你在任务 3 中进行的实现是否足够优化? 请针对这一场景实现 task4() , 再次提醒, 程序要能高效处理海量数据.
* ----------------------------------------
* Find out all the rows that sastify below conditions:
*
* ((b >= 10 && b < 50) &&
* (a == 1000 || a == 2000 || a == 3000))
*
* Print them to the terminal, one row per line, for example:
*
* 1000,20
* 1000,23
* 2000,16
*/
"""
import itertools
import multiprocessing
import time


def task1(rows):
    l = [f'{a!s},{b!s}' for i in rows if ((a := int((j := i.split(',', 1))[0])) == 1000 or a == 2000 or a == 3000) and 10 <= (b := int(j[1][:-1])) < 50]
    print('\n'.join(l))


def task2(rows):
    task1(rows)


def task3(rows):
    l = [(a, b) for i in rows if ((a := int((j := i.split(',', 1))[0])) == 1000 or a == 2000 or a == 3000) and 10 <= (b := int(j[1][:-1])) < 50]
    l.sort(key=lambda x: x[1])
    print('\n'.join([f'{i[0]!s},{i[1]!s}' for i in l]))


def task4(rows):
    l = [(a, b) for i in rows if (a := int((j := i.split(',', 1))[0])) % 1000 == 0 and 10 <= (b := int(j[1][:-1])) < 50]
    l.sort(key=lambda x: x[1])
    print('\n'.join([f'{i[0]!s},{i[1]!s}' for i in l]))


def split_corpus(path, shard_size):
    with open(path, "r") as f:
        if shard_size <= 0:
            yield f.readlines()
        else:
            while True:
                shard = list(itertools.islice(f, shard_size))
                if not shard:
                    break
                yield shard


if __name__ == '__main__':
    pool = multiprocessing.Pool(processes=5)
    t1 = time.time()
    no = 0
    for rs in split_corpus('rows.txt', 10000000):
        no += 1
        pool.apply_async(task1, (rs, ))
        print(no)
        # task1(rs)
    pool.close()
    pool.join()
    print('no: ', no, ', cost:', time.time() - t1)
```
